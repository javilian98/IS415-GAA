[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "Javier’s IS415-GAA Website\nWelcome to IS415 Geospatial Analytics and Applications. In this website, you will find my coursework and learning journey prepared for this course."
  },
  {
    "objectID": "Take-home_Ex/takehome_1.html",
    "href": "Take-home_Ex/takehome_1.html",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "Millions of people have their lives shattered by armed conflict – wars – every year.\nArmed conflict has been on the rise since about 2012, after a decline in the 1990s and early 2000s. First came conflicts in Libya, Syria and Yemen, triggered by the 2011 Arab uprisings. Libya’s instability spilled south, helping set off a protracted crisis in the Sahel region. A fresh wave of major combat followed: the 2020 Azerbaijani-Armenian war over the Nagorno-Karabakh enclave, horrific fighting in Ethiopia’s northern Tigray region that began weeks later, the conflict prompted by the Myanmar army’s 2021 power grab and Russia’s 2022 assault on Ukraine. Add to those 2023’s devastation in Sudan and Gaza. Around the globe, more people are dying in fighting, being forced from their homes or in need of life-saving aid than in decades."
  },
  {
    "objectID": "Take-home_Ex/takehome_1.html#introduction",
    "href": "Take-home_Ex/takehome_1.html#introduction",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "Millions of people have their lives shattered by armed conflict – wars – every year.\nArmed conflict has been on the rise since about 2012, after a decline in the 1990s and early 2000s. First came conflicts in Libya, Syria and Yemen, triggered by the 2011 Arab uprisings. Libya’s instability spilled south, helping set off a protracted crisis in the Sahel region. A fresh wave of major combat followed: the 2020 Azerbaijani-Armenian war over the Nagorno-Karabakh enclave, horrific fighting in Ethiopia’s northern Tigray region that began weeks later, the conflict prompted by the Myanmar army’s 2021 power grab and Russia’s 2022 assault on Ukraine. Add to those 2023’s devastation in Sudan and Gaza. Around the globe, more people are dying in fighting, being forced from their homes or in need of life-saving aid than in decades."
  },
  {
    "objectID": "Take-home_Ex/takehome_1.html#the-objectives",
    "href": "Take-home_Ex/takehome_1.html#the-objectives",
    "title": "Take-home Exercise 1",
    "section": "The Objectives",
    "text": "The Objectives\n\nGain a better insight of the safety of civilians in Myanmar by knowing which hour of the day is dangerous to be outside"
  },
  {
    "objectID": "Take-home_Ex/takehome_1.html#the-data",
    "href": "Take-home_Ex/takehome_1.html#the-data",
    "title": "Take-home Exercise 1",
    "section": "The Data",
    "text": "The Data\n\nArmed conflict data\nFor the purpose of this assignment, armed conflict data of Myanmar between 2021-2024 from Armed Conflict Location & Event Data (ACLED), an independent, impartial, international non-profit organization collecting data on violent conflict and protest in all countries and territories in the world, should be used.\nIn terms of event types, students should focus on at least four main event types, namely: Battles, Explosions/Remote Violence, Strategic developments, and Violence against civilians.\nIn terms of study period, students should focus on quarterly armed conflict events from January 2021 until June 2024.\n\n\nGIS Data\n\nGeospatial data on Myanmar Information Management Unit, MIMU"
  },
  {
    "objectID": "Take-home_Ex/takehome_1.html#installing-and-loading-the-r-packages",
    "href": "Take-home_Ex/takehome_1.html#installing-and-loading-the-r-packages",
    "title": "Take-home Exercise 1",
    "section": "Installing and Loading the R packages",
    "text": "Installing and Loading the R packages\nIn this hands-on exercise, five R packages will be used, they are:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nsparr, provides functions to estimate fixed and adaptive kernel-smoothed spatial relative risk surfaces via the density-ratio method and perform subsequent inference. Fixed-bandwidth spatiotemporal density and relative risk estimation is also supported.\nraster which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\nmaptools which provides a set of tools for manipulating geographic data. In this hands-on exercise, we mainly use it to convert Spatial objects into ppp format of spatstat.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\nUse the code chunk below to install and launch the five R packages.\n\npacman::p_load(sf, raster, spatstat, sparr, tmap, tidyverse)"
  },
  {
    "objectID": "Take-home_Ex/takehome_1.html#importing-spatial-data-file",
    "href": "Take-home_Ex/takehome_1.html#importing-spatial-data-file",
    "title": "Take-home Exercise 1",
    "section": "Importing Spatial Data File",
    "text": "Importing Spatial Data File\n\nacled &lt;- readr::read_csv(\"data/aspatial/ACLED_Myanmar.csv\")\n\nRows: 51553 Columns: 31\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (20): event_id_cnty, event_date, disorder_type, event_type, sub_event_ty...\ndbl (11): year, time_precision, inter1, inter2, interaction, iso, latitude, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Take-home_Ex/takehome_1.html#importing-geospatial-data-files",
    "href": "Take-home_Ex/takehome_1.html#importing-geospatial-data-files",
    "title": "Take-home Exercise 1",
    "section": "Importing Geospatial Data Files",
    "text": "Importing Geospatial Data Files\n\nmpsz_adm1_sf &lt;- st_read(\n  dsn = \"data/geospatial/admin1\",\n  layer = \"mmr_polbnda_adm1_250k_mimu_1\"\n) %&gt;%\n  st_transform(crs = 32647)\n\nReading layer `mmr_polbnda_adm1_250k_mimu_1' from data source \n  `C:\\javilian98\\IS415-GAA\\Take-home_Ex\\data\\geospatial\\admin1' \n  using driver `ESRI Shapefile'\nSimple feature collection with 15 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Take-home_Ex/takehome_1.html#constant-variables",
    "href": "Take-home_Ex/takehome_1.html#constant-variables",
    "title": "Take-home Exercise 1",
    "section": "Constant Variables",
    "text": "Constant Variables\n\n### Constants\n# Define a named vector for event types\nevent_types &lt;- c(\n  \"VIOLENCE_CIVILIANS\" = \"Violence against civilians\",\n  \"BATTLES\" = \"Battles\",\n  \"STRAT_DEVS\" = \"Strategic developments\",\n  \"EXPLOSIONS_REMOTE_VIOLENCE\" = \"Explosions/Remote violence\"\n)\n\n# List of years and quarters\nCONST_YEARS &lt;- 2021:2024\nCONST_QUARTERS &lt;- 1:4"
  },
  {
    "objectID": "Take-home_Ex/takehome_1.html#geospatial-data-wrangling",
    "href": "Take-home_Ex/takehome_1.html#geospatial-data-wrangling",
    "title": "Take-home Exercise 1",
    "section": "Geospatial Data wrangling",
    "text": "Geospatial Data wrangling\n\nInspecting columns\n\ncolnames(acled)\n\n [1] \"event_id_cnty\"      \"event_date\"         \"year\"              \n [4] \"time_precision\"     \"disorder_type\"      \"event_type\"        \n [7] \"sub_event_type\"     \"actor1\"             \"assoc_actor_1\"     \n[10] \"inter1\"             \"actor2\"             \"assoc_actor_2\"     \n[13] \"inter2\"             \"interaction\"        \"civilian_targeting\"\n[16] \"iso\"                \"region\"             \"country\"           \n[19] \"admin1\"             \"admin2\"             \"admin3\"            \n[22] \"location\"           \"latitude\"           \"longitude\"         \n[25] \"geo_precision\"      \"source\"             \"source_scale\"      \n[28] \"notes\"              \"fatalities\"         \"tags\"              \n[31] \"timestamp\"         \n\nncol(acled)\n\n[1] 31\n\n\n\n\nDropping unused columns\n\nacled &lt;- acled %&gt;%\n  select(-iso, -region, -country, -notes, -time_precision)\n\nInspecting columns again\n\ncolnames(acled)\n\n [1] \"event_id_cnty\"      \"event_date\"         \"year\"              \n [4] \"disorder_type\"      \"event_type\"         \"sub_event_type\"    \n [7] \"actor1\"             \"assoc_actor_1\"      \"inter1\"            \n[10] \"actor2\"             \"assoc_actor_2\"      \"inter2\"            \n[13] \"interaction\"        \"civilian_targeting\" \"admin1\"            \n[16] \"admin2\"             \"admin3\"             \"location\"          \n[19] \"latitude\"           \"longitude\"          \"geo_precision\"     \n[22] \"source\"             \"source_scale\"       \"fatalities\"        \n[25] \"tags\"               \"timestamp\"         \n\nncol(acled)\n\n[1] 26\n\n\n\n\nConverting timezone to Yangon, Myanmar\n\nacled$timestamp &lt;- as_datetime(acled$timestamp, tz = \"Asia/Yangon\")\n\nExtract the Hour, Minutes and Seconds into their new respective columns from the timestamp column to be used later.\n\nacled &lt;- acled %&gt;%\n  mutate(\n    Hour = hour(timestamp),\n    Minutes = minute(timestamp),\n    Seconds = second(timestamp)\n  )\n\nNow we are going to convert the longitude and latitude to CRS system of Myanmar, and extract the month number to a new Month_num column. Likewise for quarter number into Quarter_num column.\n\nacled_sf &lt;- acled %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %&gt;%\n  st_transform(crs = 32647) %&gt;%\n  mutate(\n    event_date = dmy(event_date),\n    Month_num = month(event_date),\n    Quarter_num = quarter(event_date)\n  )\n\n\n\nOrganising Data: Split data into years and quarters\nSeparate data into years 2021-2024\n\nacled_sf_2021 &lt;- acled_sf %&gt;%\n  filter(year == 2021)\n\nacled_sf_2022 &lt;- acled_sf %&gt;%\n  filter(year == 2022)\n\nacled_sf_2023 &lt;- acled_sf %&gt;%\n  filter(year == 2023)\n\nacled_sf_2024 &lt;- acled_sf %&gt;%\n  filter(year == 2024)\n\nSeparate data from each year to quarters Q1-Q4\n\nacled_sf_2021_q1 &lt;- acled_sf_2021 %&gt;%\n  filter(quarters(event_date) == \"Q1\")\nacled_sf_2021_q2 &lt;- acled_sf_2021 %&gt;%\n  filter(quarters(event_date) == \"Q2\")\nacled_sf_2021_q3 &lt;- acled_sf_2021 %&gt;%\n  filter(quarters(event_date) == \"Q3\")\nacled_sf_2021_q4 &lt;- acled_sf_2021 %&gt;%\n  filter(quarters(event_date) == \"Q4\")\n\nacled_sf_2022_q1 &lt;- acled_sf_2022 %&gt;%\n  filter(quarters(event_date) == \"Q1\")\nacled_sf_2022_q2 &lt;- acled_sf_2022 %&gt;%\n  filter(quarters(event_date) == \"Q2\")\nacled_sf_2022_q3 &lt;- acled_sf_2022 %&gt;%\n  filter(quarters(event_date) == \"Q3\")\nacled_sf_2022_q4 &lt;- acled_sf_2022 %&gt;%\n  filter(quarters(event_date) == \"Q4\")\n\nacled_sf_2023_q1 &lt;- acled_sf_2023 %&gt;%\n  filter(quarters(event_date) == \"Q1\")\nacled_sf_2023_q2 &lt;- acled_sf_2023 %&gt;%\n  filter(quarters(event_date) == \"Q2\")\nacled_sf_2023_q3 &lt;- acled_sf_2023 %&gt;%\n  filter(quarters(event_date) == \"Q3\")\nacled_sf_2023_q4 &lt;- acled_sf_2023 %&gt;%\n  filter(quarters(event_date) == \"Q4\")\n\nacled_sf_2024_q1 &lt;- acled_sf_2024 %&gt;%\n  filter(quarters(event_date) == \"Q1\")\nacled_sf_2024_q2 &lt;- acled_sf_2024 %&gt;%\n  filter(quarters(event_date) == \"Q2\")\n\n\n\nDivde data based on event types\n\nHelper function to derive data based on our types.\nGiven the nature of the task which is to study each event data per quarter of each year, there will be a lot of repetitive codes by the end of this exercise. So the benefits it provides is an organised and reusable piece of code snippet that allows you to apply to other sets of data by changing certain arguments.\n\n### Helper functions\nget_quarter_data_from_event_type &lt;- function(data, event_type_arg) {\n  # Filter the data based on the specified event_type\n  filtered_data &lt;- data %&gt;%\n    group_by(admin1) %&gt;%\n    filter(event_type == event_type_arg) %&gt;%\n    select(Quarter_num) %&gt;%\n  \n  # Return the filtered data\n  return(filtered_data)\n}\n\npopulate_quarter_data_from_event_type &lt;- function(event_type, data_list_name, years, quarters) {\n  # Initialize an empty list to store the results\n  event_data_list &lt;- list()\n  \n  # Loop over the years and quarters to populate the list\n  for (year in years) {\n    for (quarter in quarters) {\n      if (year == 2024 && quarter &gt; 2) next  # Skip quarters beyond Q2 for 2024\n      \n      # Construct the variable name dynamically\n      var_name &lt;- paste0(year, \"_q\", quarter)\n      data_var_name &lt;- paste0(\"acled_sf_\", year, \"_q\", quarter)\n      \n      # Get the event type data and store it in the list\n      event_data_list[[var_name]] &lt;- get_quarter_data_from_event_type(\n        get(data_var_name),\n        event_type\n      )\n    }\n  }\n  \n  # Assign the populated list to the specified list name\n  assign(data_list_name, event_data_list, envir = .GlobalEnv)\n}\n\nNow with the help of the helper functions created, we are going to get all the the four event type data separated by quarters of each year.\n\nViolence Against CiviliansExplosions/Remote ViolenceStrategic DevelopmentsBattles\n\n\n\npopulate_quarter_data_from_event_type(\n  event_types[\"VIOLENCE_CIVILIANS\"], \n  \"violence_civilians_sf\",\n  CONST_YEARS, \n  CONST_QUARTERS\n)\n\n\n\n\npopulate_quarter_data_from_event_type(\n  event_types[\"EXPLOSIONS_REMOTE_VIOLENCE\"], \n  \"explosions_remote_violence_sf\",\n  CONST_YEARS, \n  CONST_QUARTERS\n)\n\n\n\n\npopulate_quarter_data_from_event_type(\n  event_types[\"STRAT_DEVS\"], \n  \"strat_devs_sf\",\n  CONST_YEARS, \n  CONST_QUARTERS\n)\n\n\n\n\npopulate_quarter_data_from_event_type(\n  event_types[\"BATTLES\"], \n  \"battles_sf\",\n  CONST_YEARS, \n  CONST_QUARTERS\n)\n\n\n\n\n\n\n\nConverting sf format into spatstat’s ppp format\nspatstat requires the analytical data in ppp object form. We will write a helper function to convert each list of data from event types to PPP format.\n\nHelper functions to converrt sf to ppp\n\nconvert_to_ppp &lt;- function(data_list_name, sf_list, years, quarters) {\n  # Initialize an empty list to store the results\n  event_data_list &lt;- list()\n  \n  # Loop over the years and quarters to populate the list\n  for (year in years) {\n    for (quarter in quarters) {\n      if (year == 2024 && quarter &gt; 2) next  # Skip quarters beyond Q2 for 2024\n      \n      # Construct the variable name dynamically\n      var_name &lt;- paste0(year, \"_q\", quarter)\n      \n      # Get the event type data and store it in the list\n      event_data_list[[var_name]] &lt;- as.ppp(sf_list[[var_name]])\n    }\n  }\n  \n  # Assign the populated list to the specified list name\n  assign(data_list_name, event_data_list, envir = .GlobalEnv)\n}\n\n\nconvert_to_ppp(\"violence_civilians_ppp\", violence_civilians_sf, CONST_YEARS, CONST_QUARTERS)\nconvert_to_ppp(\"explosions_remote_violence_ppp\", explosions_remote_violence_sf, CONST_YEARS, CONST_QUARTERS)\nconvert_to_ppp(\"strat_devs_ppp\", strat_devs_sf, CONST_YEARS, CONST_QUARTERS)\nconvert_to_ppp(\"battles_ppp\", battles_sf, CONST_YEARS, CONST_QUARTERS)\n\nNow, let us plot and have a look at the data of Q1 2021 from the list violence_civilians_ppp.\n\nplot(violence_civilians_ppp[[\"2021_q1\"]])\n\n\n\n\n\n\n\n\n\nsummary(violence_civilians_ppp[[\"2021_q1\"]])\n\nMarked planar point pattern:  147 points\nAverage intensity 1.609184e-10 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 13 decimal places\n\nmarks are numeric, of type 'integer'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      1       1       1       1       1       1 \n\nWindow: rectangle = [-180845.7, 456560.5] x [1375186.1, 2808348.1] units\n                    (637400 x 1433000 units)\nWindow area = 9.13506e+11 square units\n\n\nNotice the warning message about duplicates. In spatial point patterns analysis an issue of significant is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident.\n\n\n\nEvaluate duplicate points\nWe can check the duplication in a ppp object by using the code chunk below.\n\nany(duplicated(violence_civilians_ppp[[\"2021_q1\"]]))\n\n[1] TRUE\n\n\n\n\nRemoving duplicated points\nWe will use jitterirng to curb the duplicates for all the data.\n\nHelper function to remove duplicates\n\nremove_duplicates &lt;- function(data_list_name, ppp_list, years, quarters) {\n  # Initialize an empty list to store the results\n  event_data_list &lt;- list()\n  \n  # Loop over the years and quarters to populate the list\n  for (year in years) {\n    for (quarter in quarters) {\n      if (year == 2024 && quarter &gt; 2) next  # Skip quarters beyond Q2 for 2024\n      \n      # Construct the variable name dynamically\n      var_name &lt;- paste0(year, \"_q\", quarter)\n      \n      # Get the event type data and store it in the list\n      event_data_list[[var_name]] &lt;- rjitter(ppp_list[[var_name]], retry=TRUE, nsim=1, drop=TRUE)\n    }\n  }\n  \n  # Assign the populated list to the specified list name\n  assign(data_list_name, event_data_list, envir = .GlobalEnv)\n}\n\n\nremove_duplicates(\"violence_civilians_ppp\", violence_civilians_ppp, CONST_YEARS, CONST_QUARTERS)\nremove_duplicates(\"explosions_remote_violence_ppp\", explosions_remote_violence_ppp, CONST_YEARS, CONST_QUARTERS)\nremove_duplicates(\"strat_devs_ppp\", strat_devs_ppp, CONST_YEARS, CONST_QUARTERS)\nremove_duplicates(\"battles_ppp\", battles_ppp, CONST_YEARS, CONST_QUARTERS)\n\n\n\n\nEvaluate duplicate points again\nWe have removed all the duplicates as you can see from the output below.\n\nany(duplicated(violence_civilians_ppp[[\"2021_q1\"]]))\n\n[1] FALSE\n\n\n\n\nCreating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Mynanmar boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to convert the SpatialPolygon object into owin object of spatstat.\n\nmpsz_adm1_owin &lt;- as.owin(mpsz_adm1_sf)\nmpsz_adm1_owin\n\nwindow: polygonal boundary\nenclosing rectangle: [-210008.6, 724647.6] x [1072026.3, 3158467.1] units\n\n\n\n\nCombining point events object and owin object\n\nHelper functions for combining ppp obj with owin obj, and plotting them.\nIn this last step of geospatial data wrangling, we will combine the owin object with the PPP list of data.\n\ncombine_ppp_with_owin &lt;- function(data_list_name, ppp_list, owin_obj, years, quarters) {\n  # Initialize an empty list to store the results\n  event_data_list &lt;- list()\n  \n  # Loop over the years and quarters to populate the list\n  for (year in years) {\n    for (quarter in quarters) {\n      if (year == 2024 && quarter &gt; 2) next  # Skip quarters beyond Q2 for 2024\n      \n      # Construct the variable name dynamically\n      var_name &lt;- paste0(year, \"_q\", quarter)\n      \n      # Get the event type data and store it in the list\n      event_data_list[[var_name]] &lt;- ppp_list[[var_name]][owin_obj]\n    }\n  }\n  \n  # Assign the populated list to the specified list name\n  assign(data_list_name, event_data_list, envir = .GlobalEnv)\n}\n\n# Helper function to plot the list of  data\n\nhelper_func_plot_list &lt;- function(kde_list) {\n  for (name in names(kde_list)) {\n    plot(kde_list[[name]], main = name)\n  }\n}\n\n\nViolence Against CiviliansExplosions/Remote Violence\n\n\n\ncombine_ppp_with_owin(\"violence_civilians_ppp\", violence_civilians_ppp, mpsz_adm1_owin, CONST_YEARS, CONST_QUARTERS)\n\n\nhelper_func_plot_list(violence_civilians_ppp)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncombine_ppp_with_owin(\n  \"explosions_remote_violence_ppp\", \n  explosions_remote_violence_ppp, \n  mpsz_adm1_owin, \n  CONST_YEARS, \n  CONST_QUARTERS\n)\n\n\nhelper_func_plot_list(explosions_remote_violence_ppp)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStrategic Developments\n\ncombine_ppp_with_owin(\"strat_devs_ppp\", strat_devs_ppp, mpsz_adm1_owin, CONST_YEARS, CONST_QUARTERS)\n\n\nhelper_func_plot_list(strat_devs_ppp)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBattles\n\ncombine_ppp_with_owin(\"battles_ppp\", battles_ppp, mpsz_adm1_owin, CONST_YEARS, CONST_QUARTERS)\n\n\nhelper_func_plot_list(battles_ppp)"
  },
  {
    "objectID": "Take-home_Ex/takehome_1.html#deriving-kde-layers-for-event-types",
    "href": "Take-home_Ex/takehome_1.html#deriving-kde-layers-for-event-types",
    "title": "Take-home Exercise 1",
    "section": "Deriving KDE layers for Event Types",
    "text": "Deriving KDE layers for Event Types\n\nRescaling unit measurement to km\nIn the code chunk below, the helper function is used to covert the unit of measurement from meter to kilometer.\n\nHelper function to rescale unit measurement to km\n\nrescale_to_km &lt;- function(data_list_name, ppp_list, years, quarters) {\n  # Initialize an empty list to store the results\n  event_data_list &lt;- list()\n  \n  # Loop over the years and quarters to populate the list\n  for (year in years) {\n    for (quarter in quarters) {\n      if (year == 2024 && quarter &gt; 2) next  # Skip quarters beyond Q2 for 2024\n      \n      # Construct the variable name dynamically\n      var_name &lt;- paste0(year, \"_q\", quarter)\n      \n      # Get the event type data and store it in the list\n      event_data_list[[var_name]] &lt;- rescale.ppp(ppp_list[[var_name]], 1000, \"km\")\n    }\n  }\n  \n  # Assign the populated list to the specified list name\n  assign(data_list_name, event_data_list, envir = .GlobalEnv)\n}\n\n\nrescale_to_km(\"violence_civilians_ppp_km\", violence_civilians_ppp, CONST_YEARS, CONST_QUARTERS)\nrescale_to_km(\"explosions_remote_violence_ppp_km\", explosions_remote_violence_ppp, CONST_YEARS, CONST_QUARTERS)\nrescale_to_km(\"strat_devs_ppp_km\", strat_devs_ppp, CONST_YEARS, CONST_QUARTERS)\nrescale_to_km(\"battles_ppp_km\", battles_ppp, CONST_YEARS, CONST_QUARTERS)\n\n\n\n\nComputing KDE layers for Event Types\nHelper function for computing KDE\n\nhelper_func_process_kde &lt;- function(data_list_name, ppp_list, years, quarters, kernel_type, sigma_type) {\n  # Initialize an empty list to store the results\n  event_data_list &lt;- list()\n  \n  # Loop over the years and quarters to populate the list\n  for (year in years) {\n    for (quarter in quarters) {\n      if (year == 2024 && quarter &gt; 2) next  # Skip quarters beyond Q2 for 2024\n      \n      # Construct the variable name dynamically\n      var_name &lt;- paste0(year, \"_q\", quarter)\n      \n      # Get the event type data and store it in the list\n      event_data_list[[var_name]] = density(\n        ppp_list[[var_name]],\n        sigma = sigma_type,\n        edge = TRUE,\n        kernel = kernel_type,\n        main = paste(year, \"Q\", quarter)\n      )\n    }\n  }\n  \n  # Assign the populated list to the specified list name\n  assign(data_list_name, event_data_list, envir = .GlobalEnv)\n}\n\n\nI have tried using automatic bandwidth selection methods however, due to the performance limitations of my computer, it took extremely long to compute every single data.\nMy alternative solution is to play around using fixed bandwidth, and the value of 10 seemed to give a decent visualisation of the plots.\n\n\nViolence Against CiviliansExplosion & Remote ViolenceStrategic DevelopmentsBattles\n\n\n\nsigma_value &lt;- 10\n\nhelper_func_process_kde(\n  \"kde_list_violence_civilians\",\n  violence_civilians_ppp_km,\n  CONST_YEARS, \n  CONST_QUARTERS, \n  \"gaussian\", \n  sigma_value\n)\n\n\n\n\nsigma_value &lt;- 10\n\nhelper_func_process_kde(\n  \"kde_list_explosions_remote_violence\",\n  explosions_remote_violence_ppp_km, \n  CONST_YEARS, \n  CONST_QUARTERS,\n  \"gaussian\",\n  sigma_value\n)\n\n\n\n\nsigma_value &lt;- 10\n\nhelper_func_process_kde(\n  \"kde_list_strat_devs\",\n  strat_devs_ppp_km,\n  CONST_YEARS,\n  CONST_QUARTERS,\n  \"gaussian\",\n  sigma_value\n)\n\n\n\n\nsigma_value &lt;- 10\n\nhelper_func_process_kde(\n  \"kde_list_battles\",\n  battles_ppp_km,\n  CONST_YEARS, \n  CONST_QUARTERS, \n  \"gaussian\", \n  sigma_value\n)\n\n\n\n\n\n\nVisualising KDE Layers\nHelper function for plotting the KDE Layers\n\nhelper_func_plot_kde_list &lt;- function(kde_list, xlab = \"Distance (km)\", ylab = \"Density\") {\n  for (name in names(kde_list)) {\n    plot(kde_list[[name]], main = name, xlab = xlab, ylab = ylab)\n  }\n}\n\n\nViolence Against CiviliansExplosions/Remote ViolenceStrategic DevelopmentsBattles\n\n\n\nhelper_func_plot_kde_list(kde_list_violence_civilians)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhelper_func_plot_kde_list(kde_list_violence_civilians)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhelper_func_plot_kde_list(kde_list_strat_devs)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhelper_func_plot_kde_list(kde_list_battles)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKDE Insights\nBased on the above KDE layers, it shows that there is always a concentration in each plot of heatmap that starts of in Sagaing state of Myanmar then it radiates to other states, and Q3 of year 2023 has the highest intensity in the map."
  },
  {
    "objectID": "Take-home_Ex/takehome_1.html#nd-order-spatial-point-patterns-analysis",
    "href": "Take-home_Ex/takehome_1.html#nd-order-spatial-point-patterns-analysis",
    "title": "Take-home Exercise 1",
    "section": "2nd-order spatial point patterns analysis",
    "text": "2nd-order spatial point patterns analysis\nNext, we will conduct our 2nd-order spatial point patterns analysis. But the computation levels and requirements will increase significantly. Hence, they are more appropriate for local view such as at the state level.\nIn that case, let us find which state has the most number of occurrences in the acled_sf variable.\n\nsummary &lt;- acled_sf %&gt;%\n  group_by(admin1) %&gt;%\n  summarise(count = n()) %&gt;%\n  arrange(desc(count))\n\nsummary\n\nSimple feature collection with 18 features and 2 fields\nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: -208804.4 ymin: 1103500 xmax: 640934.5 ymax: 3042960\nProjected CRS: WGS 84 / UTM zone 47N\n# A tibble: 18 × 3\n   admin1      count                                                    geometry\n   &lt;chr&gt;       &lt;int&gt;                                            &lt;MULTIPOINT [m]&gt;\n 1 Sagaing     14043 ((-16397.05 2576482), (-13816.45 2549666), (-13808.2 25332…\n 2 Mandalay     5047 ((68129.21 2320839), (69197.66 2321843), (69550.81 2329036…\n 3 Magway       4585 ((-14448.48 2310133), (-11811.97 2503484), (-11778.42 2331…\n 4 Yangon       3893 ((148595 1924891), (149693.3 1924406), (161280.2 1841113),…\n 5 Shan-North   3435 ((217854 2555977), (229100.8 2553686), (237609.2 2472369),…\n 6 Kachin       3198 ((195339.5 2804590), (203637.2 2823909), (208746.8 2822422…\n 7 Tanintharyi  2850 ((383968.4 1610809), (384739.6 1614423), (389620.5 1590573…\n 8 Rakhine      2343 ((-208804.4 2357274), (-207135 2358896), (-206931.7 235949…\n 9 Kayin        1992 ((233276 2137205), (235185 2133257), (236637.1 2129658), (…\n10 Mon          1878 ((274988.3 1941700), (275098 1944865), (275324.9 1930892),…\n11 Chin         1742 ((-156265.4 2407840), (-152350.3 2435531), (-151082.3 2423…\n12 Shan-South   1534 ((221551.2 2321401), (229883.3 2328254), (231506.5 2346187…\n13 Bago-East    1400 ((196713.9 2122389), (204976.2 2126874), (207611 2124472),…\n14 Kayah        1398 ((279858.3 2139472), (283918.5 2160815), (285121.8 2165750…\n15 Ayeyarwady   1062 ((-1808.855 1832416), (1429.168 1776303), (1438.857 183487…\n16 Bago-West     718 ((78145.15 2073712), (79398.46 2070678), (81116.12 2070440…\n17 Nay Pyi Taw   340 ((168739.4 2244682), (180557.3 2184994), (180562.1 2184673…\n18 Shan-East      95 ((489266.8 2244252), (502198.1 2360984), (526697.7 2270740…\n\n\nBased on the summary data above, Sagaing has the most number of counts in the entire acled_sf data. So let us filter down the data to related to Sagaing.\nHelper functions Filter by state\n\nCOUNTRY_STATE &lt;- \"Sagaing\"\n\nget_quarter_data_by_state &lt;- function(data, state_arg, event_type_arg) {\n  # Filter the data based on the specified event_type\n  filtered_data &lt;- data %&gt;%\n    group_by(admin1) %&gt;%\n    filter(\n      (admin1 == state_arg) &\n      (event_type == event_type_arg)\n    ) %&gt;%\n    select(Quarter_num)\n  \n  # Return the filtered data\n  return(filtered_data)\n}\n\npopulate_quarter_data_by_state &lt;- function(event_type, data_list_name, years, quarters, country_state) {\n  # Initialize an empty list to store the results\n  event_data_list &lt;- list()\n  \n  # Loop over the years and quarters to populate the list\n  for (year in years) {\n    for (quarter in quarters) {\n      if (year == 2024 && quarter &gt; 2) next  # Skip quarters beyond Q2 for 2024\n      \n      # Construct the variable name dynamically\n      var_name &lt;- paste0(year, \"_q\", quarter)\n      data_var_name &lt;- paste0(\"acled_sf_\", year, \"_q\", quarter)\n      \n      # Get the event type data and store it in the list\n      event_data_list[[var_name]] &lt;- get_quarter_data_by_state(\n        get(data_var_name),\n        country_state,\n        event_type\n      )\n    }\n  }\n  \n  # Assign the populated list to the specified list name\n  assign(data_list_name, event_data_list, envir = .GlobalEnv)\n}\n\nNow let us generate a list of data for each event types in Sagaing.\n\nViolence Against CiviliansExplosions/Remote ViolenceStrategic DevelopmentsBattles\n\n\n\npopulate_quarter_data_by_state(\n  event_types[\"VIOLENCE_CIVILIANS\"], \n  \"violence_civilians_state_sf\",\n  CONST_YEARS, \n  CONST_QUARTERS, \n  COUNTRY_STATE\n)\n\n\n\n\npopulate_quarter_data_by_state(\n  event_types[\"EXPLOSIONS_REMOTE_VIOLENCE\"], \n  \"explosions_remote_violence_state_sf\",\n  CONST_YEARS, \n  CONST_QUARTERS, \n  COUNTRY_STATE\n)\n\n\n\n\npopulate_quarter_data_by_state(\n  event_types[\"STRAT_DEVS\"], \n  \"strat_devs_state_sf\",\n  CONST_YEARS, \n  CONST_QUARTERS, \n  COUNTRY_STATE\n)\n\n\n\n\npopulate_quarter_data_by_state(\n  event_types[\"BATTLES\"], \n  \"battles_state_sf\",\n  CONST_YEARS, \n  CONST_QUARTERS, \n  COUNTRY_STATE\n)\n\n\n\n\n\nConvert to PPP from sf\nBefore we can perform our 2nd Order spacial point patterns analysis, we’ll need to convert our sf data of Sagaing into ppp format.\n\nconvert_to_ppp(\"violence_civilians_state_ppp\", violence_civilians_state_sf, CONST_YEARS, CONST_QUARTERS)\nconvert_to_ppp(\"explosions_remote_violence_state_ppp\", explosions_remote_violence_state_sf, CONST_YEARS, CONST_QUARTERS)\nconvert_to_ppp(\"strat_devs_state_ppp\", strat_devs_state_sf, CONST_YEARS, CONST_QUARTERS)\nconvert_to_ppp(\"battles_state_ppp\", battles_state_sf, CONST_YEARS, CONST_QUARTERS)\n\n\nclass(violence_civilians_state_ppp[[\"2021_q1\"]])\n\n[1] \"ppp\"\n\n\n\n\nRemoving duplicated ppp points\nWe also need to remove any possible duplicates in the list of data.\n\nany(duplicated(violence_civilians_state_ppp[[\"2021_q1\"]]))\n\n[1] TRUE\n\nany(duplicated(violence_civilians_state_ppp[[\"2021_q2\"]]))\n\n[1] TRUE\n\nany(duplicated(violence_civilians_state_ppp[[\"2021_q3\"]]))\n\n[1] TRUE\n\nany(duplicated(violence_civilians_state_ppp[[\"2021_q4\"]]))\n\n[1] TRUE\n\nany(duplicated(violence_civilians_state_ppp[[\"2022_q1\"]]))\n\n[1] TRUE\n\nany(duplicated(violence_civilians_state_ppp[[\"2022_q2\"]]))\n\n[1] TRUE\n\nany(duplicated(violence_civilians_state_ppp[[\"2022_q3\"]]))\n\n[1] TRUE\n\nany(duplicated(violence_civilians_state_ppp[[\"2022_q4\"]]))\n\n[1] TRUE\n\nany(duplicated(violence_civilians_state_ppp[[\"2023_q1\"]]))\n\n[1] TRUE\n\nany(duplicated(violence_civilians_state_ppp[[\"2023_q2\"]]))\n\n[1] TRUE\n\nany(duplicated(violence_civilians_state_ppp[[\"2023_q3\"]]))\n\n[1] TRUE\n\nany(duplicated(violence_civilians_state_ppp[[\"2023_q4\"]]))\n\n[1] TRUE\n\nany(duplicated(violence_civilians_state_ppp[[\"2024_q1\"]]))\n\n[1] TRUE\n\nany(duplicated(violence_civilians_state_ppp[[\"2024_q2\"]]))\n\n[1] TRUE\n\n\n\nremove_duplicates(\"violence_civilians_state_ppp\", violence_civilians_ppp, CONST_YEARS, CONST_QUARTERS)\nremove_duplicates(\"explosions_remote_violence_state_ppp\", explosions_remote_violence_ppp, CONST_YEARS, CONST_QUARTERS)\nremove_duplicates(\"strat_devs_state_ppp\", strat_devs_ppp, CONST_YEARS, CONST_QUARTERS)\nremove_duplicates(\"battles_state_ppp\", battles_ppp, CONST_YEARS, CONST_QUARTERS)\n\nNow we also need to make sure of unit of measurement is in kilometres too.\n\nrescale_to_km(\"violence_civilians_state_ppp_km\", violence_civilians_state_ppp, CONST_YEARS, CONST_QUARTERS)\nrescale_to_km(\"explosions_remote_violence_state_ppp_km\", explosions_remote_violence_state_ppp, CONST_YEARS, CONST_QUARTERS)\nrescale_to_km(\"strat_devs_state_ppp_km\", strat_devs_state_ppp, CONST_YEARS, CONST_QUARTERS)\nrescale_to_km(\"battles_state_ppp_km\", battles_state_ppp, CONST_YEARS, CONST_QUARTERS)\n\n\nviolence_civilians_state_ppp_km[[\"2021_q1\"]]\n\nMarked planar point pattern: 137 points\nmarks are numeric, of storage type  'integer'\nwindow: polygonal boundary\nenclosing rectangle: [-210.0086, 724.6476] x [1072.0263, 3158.4671] km\n\n\n\n\nAnalysing Spatial Point Process Using F function\nThe F function estimates the empty space function F(r) or its hazard rate h(r) from a point pattern in a window of arbitrary shape.\nWe will compute F-function estimation by using Fest() of spatstat package, and also perform monte carlo simulation test using envelope() of spatstat package.\n\nHelper functions\n\ncompute_2nd_order_spa &lt;- function(Fest, data_list_name, ppp_list, years, quarters) {\n  # Initialize an empty list to store the results\n  event_data_list &lt;- list()\n  \n  # Loop over the years and quarters to populate the list\n  for (year in years) {\n    for (quarter in quarters) {\n      if (year == 2024 && quarter &gt; 2) next  # Skip quarters beyond Q2 for 2024\n      \n      # Construct the variable name dynamically\n      var_name &lt;- paste0(year, \"_q\", quarter)\n      \n      # Get the event type data and store it in the list\n      event_data_list[[var_name]] = Fest(ppp_list[[var_name]])\n    }\n  }\n  \n  # Assign the populated list to the specified list name\n  assign(data_list_name, event_data_list, envir = .GlobalEnv)\n}\n\nenvelope_2nd_order_spa &lt;- function(Fest, data_list_name, ppp_list, years, quarters) {\n  # Initialize an empty list to store the results\n  event_data_list &lt;- list()\n  \n  # Loop over the years and quarters to populate the list\n  for (year in years) {\n    for (quarter in quarters) {\n      if (year == 2024 && quarter &gt; 2) next  # Skip quarters beyond Q2 for 2024\n      \n      # Construct the variable name dynamically\n      var_name &lt;- paste0(year, \"_q\", quarter)\n      \n      # Get the event type data and store it in the list\n      event_data_list[[var_name]] &lt;- envelope(ppp_list[[var_name]], Fest, nsim = 40)\n    }\n  }\n  \n  # Assign the populated list to the specified list name\n  assign(data_list_name, event_data_list, envir = .GlobalEnv)\n}\n\n\nViolence Against CiviliansExplosions/Remote ViolenceStrategic DevelopmentsBattles\n\n\n\ncompute_2nd_order_spa(\n  Fest, \n  \"F_violence_civilians_state_ppp_km\", \n  violence_civilians_state_ppp_km, \n  CONST_YEARS, \n  CONST_QUARTERS\n)\n\nenvelope_2nd_order_spa(\n  Fest, \n  \"F_violence_civilians_state_ppp_km_csr\", \n  violence_civilians_state_ppp_km, \n  CONST_YEARS, \n  CONST_QUARTERS\n)\n\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\n\n\n\n\n\ncompute_2nd_order_spa(\n  Fest, \n  \"F_explosions_remote_violence_state_ppp_km\", \n  explosions_remote_violence_state_ppp_km, \n  CONST_YEARS, \n  CONST_QUARTERS\n)\n\nenvelope_2nd_order_spa(\n  Fest, \n  \"F_explosions_remote_violence_state_ppp_km_csr\", \n  explosions_remote_violence_state_ppp_km, \n  CONST_YEARS, \n  CONST_QUARTERS\n)\n\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\n\n\n\n\n\ncompute_2nd_order_spa(\n  Fest, \n  \"F_strat_devs_state_ppp_km\", \n  strat_devs_state_ppp_km, \n  CONST_YEARS, \n  CONST_QUARTERS\n)\n\nenvelope_2nd_order_spa(\n  Fest, \n  \"F_strat_devs_state_ppp_km_csr\", \n  strat_devs_state_ppp_km, \n  CONST_YEARS, \n  CONST_QUARTERS\n)\n\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3,\n [3:16 remaining] 4,  [3:08 remaining] 5,  [3:04 remaining] 6,\n [3:05 remaining] 7,  [2:43 remaining] 8,  [2:26 remaining] 9,\n [2:13 remaining] 10,  [2:02 remaining] 11,  [1:53 remaining] 12,\n [1:45 remaining] 13,  [1:38 remaining] 14,  [1:31 remaining] 15,\n [1:26 remaining] 16,  [1:20 remaining] 17,  [1:15 remaining] 18,\n [1:11 remaining] 19,  [1:10 remaining] 20,  [1:09 remaining] 21,\n [1:07 remaining] 22,  [1:05 remaining] 23,  [1:03 remaining] 24,\n [1:01 remaining] 25,  [1:00 remaining] 26,  [56 sec remaining] 27,\n [53 sec remaining] 28,  [50 sec remaining] 29,  [46 sec remaining] 30,\n [43 sec remaining] 31,  [39 sec remaining] 32,  [35 sec remaining] 33,\n [30 sec remaining] 34,  [25 sec remaining] 35,  [21 sec remaining] 36,\n [16 sec remaining] 37,  [12 sec remaining] 38,  [8 sec remaining] 39,\n [4 sec remaining] \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\n\n\n\n\n\ncompute_2nd_order_spa(\n  Fest, \n  \"F_battles_state_ppp_km\", \n  battles_state_ppp_km, \n  CONST_YEARS, \n  CONST_QUARTERS\n)\n\nenvelope_2nd_order_spa(\n  Fest, \n  \"F_battles_state_ppp_km_csr\", \n  battles_state_ppp_km, \n  CONST_YEARS, \n  CONST_QUARTERS\n )\n\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\n\n\n\n\n\n\n\n\nPlotting the data\nHelper function to plot the list of CSR data\n\nhelper_func_plot_csr_list &lt;- function(kde_list) {\n  for (name in names(kde_list)) {\n    plot(kde_list[[name]], main = name)\n  }\n}\n\n\nViolence Against CiviliansExplosions/Remote ViolenceStrategic DevelopmentsBattles\n\n\n\nhelper_func_plot_csr_list(F_violence_civilians_state_ppp_km_csr)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhelper_func_plot_csr_list(F_explosions_remote_violence_state_ppp_km_csr)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhelper_func_plot_csr_list(F_strat_devs_state_ppp_km_csr)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhelper_func_plot_csr_list(F_battles_state_ppp_km_csr)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG Function\nThe G function measures the distribution of the distances from an arbitrary event to its nearest event.\nWe will compute G-function estimation by using Gest() of spatstat package and perform monte carlo simulation test using envelope() of spatstat package.\n\nViolence Against CiviliansExplosions/Remote ViolenceStrategic DevelopmentsBattles\n\n\n\ncompute_2nd_order_spa(\n  Gest, \n  \"G_violence_civilians_state_ppp_km\", \n  violence_civilians_state_ppp_km, \n  CONST_YEARS, \n  CONST_QUARTERS\n)\n\nenvelope_2nd_order_spa(\n  Gest, \n  \"G_violence_civilians_state_ppp_km_csr\", \n  violence_civilians_state_ppp_km, \n  CONST_YEARS, \n  CONST_QUARTERS\n)\n\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4,  [3:15 remaining] 5,  [2:56 remaining] 6,\n [2:37 remaining] 7,  [2:24 remaining] 8,  [2:13 remaining] 9,\n [2:04 remaining] 10,  [1:58 remaining] 11,  [1:51 remaining] 12,\n [1:45 remaining] 13,  [1:44 remaining] 14,  [1:40 remaining] 15,\n [1:34 remaining] 16,  [1:29 remaining] 17,  [1:25 remaining] 18,\n [1:20 remaining] 19,  [1:16 remaining] 20,  [1:12 remaining] 21,\n [1:08 remaining] 22,  [1:05 remaining] 23,  [1:03 remaining] 24,\n [59 sec remaining] 25,  [55 sec remaining] 26,  [51 sec remaining] 27,\n [47 sec remaining] 28,  [43 sec remaining] 29,  [40 sec remaining] 30,\n [36 sec remaining] 31,  [32 sec remaining] 32,  [29 sec remaining] 33,\n [25 sec remaining] 34,  [22 sec remaining] 35,  [18 sec remaining] 36,\n [14 sec remaining] 37,  [11 sec remaining] 38,  [7 sec remaining] 39,\n [4 sec remaining] \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\n\n\n\n\n\ncompute_2nd_order_spa(\n  Gest, \n  \"G_explosions_remote_violence_state_ppp_km\", \n  explosions_remote_violence_state_ppp_km, \n  CONST_YEARS, \n  CONST_QUARTERS\n)\n\nenvelope_2nd_order_spa(\n  Gest, \n  \"G_explosions_remote_violence_state_ppp_km_csr\", \n  explosions_remote_violence_state_ppp_km, \n  CONST_YEARS, \n  CONST_QUARTERS\n)\n\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\n\n\n\n\n\ncompute_2nd_order_spa(\n  Gest, \n  \"G_strat_devs_state_ppp_km\", \n  strat_devs_state_ppp_km, \n  CONST_YEARS, \n  CONST_QUARTERS\n)\n\nenvelope_2nd_order_spa(\n  Gest, \n  \"G_strat_devs_state_ppp_km_csr\", \n  strat_devs_state_ppp_km, \n  CONST_YEARS, \n  CONST_QUARTERS\n)\n\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3,\n [3:20 remaining] 4,  [2:59 remaining] 5,  [2:50 remaining] 6,\n [2:37 remaining] 7,  [2:29 remaining] 8,  [2:25 remaining] 9,\n [2:19 remaining] 10,  [2:17 remaining] 11,  [2:14 remaining] 12,\n [2:10 remaining] 13,  [2:04 remaining] 14,  [1:59 remaining] 15,\n [1:54 remaining] 16,  [1:48 remaining] 17,  [1:43 remaining] 18,\n [1:38 remaining] 19,  [1:34 remaining] 20,  [1:29 remaining] 21,\n [1:25 remaining] 22,  [1:20 remaining] 23,  [1:16 remaining] 24,\n [1:12 remaining] 25,  [1:07 remaining] 26,  [1:02 remaining] 27,\n [58 sec remaining] 28,  [53 sec remaining] 29,  [49 sec remaining] 30,\n [44 sec remaining] 31,  [40 sec remaining] 32,  [35 sec remaining] 33,\n [31 sec remaining] 34,  [26 sec remaining] 35,  [22 sec remaining] 36,\n [18 sec remaining] 37,  [13 sec remaining] 38,  [9 sec remaining] 39,\n [4 sec remaining] \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\n\n\n\n\n\ncompute_2nd_order_spa(\n  Gest, \n  \"G_battles_state_ppp_km\", \n  battles_state_ppp_km, \n  CONST_YEARS, \n  CONST_QUARTERS\n)\n\nenvelope_2nd_order_spa(\n  Gest, \n  \"G_battles_state_ppp_km_csr\", \n  battles_state_ppp_km, \n  CONST_YEARS, \n  CONST_QUARTERS\n )\n\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2,  [3:21 remaining] 3,\n [3:14 remaining] 4,  [3:09 remaining] 5,  [3:03 remaining] 6,\n [3:03 remaining] 7,  [2:56 remaining] 8,  [2:50 remaining] 9,\n [2:44 remaining] 10,  [2:40 remaining] 11,  [2:33 remaining] 12,\n [2:25 remaining] 13,  [2:19 remaining] 14,  [2:12 remaining] 15,\n [2:06 remaining] 16,  [1:59 remaining] 17,  [1:54 remaining] 18,\n [1:48 remaining] 19,  [1:42 remaining] 20,  [1:37 remaining] 21,\n [1:32 remaining] 22,  [1:28 remaining] 23,  [1:23 remaining] 24,\n [1:18 remaining] 25,  [1:13 remaining] 26,  [1:08 remaining] 27,\n [1:03 remaining] 28,  [58 sec remaining] 29,  [53 sec remaining] 30,\n [48 sec remaining] 31,  [43 sec remaining] 32,  [39 sec remaining] 33,\n [34 sec remaining] 34,  [30 sec remaining] 35,  [25 sec remaining] 36,\n [19 sec remaining] 37,  [15 sec remaining] 38,  [10 sec remaining] 39,\n [5 sec remaining] \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\nGenerating 40 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, \n40.\n\nDone.\n\n\n\n\n\n\nViolence Against CiviliansExplosions/Remote ViolenceStrategic DevelopmentsBattles\n\n\n\nhelper_func_plot_csr_list(G_violence_civilians_state_ppp_km_csr)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhelper_func_plot_csr_list(G_explosions_remote_violence_state_ppp_km_csr)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhelper_func_plot_csr_list(G_strat_devs_state_ppp_km_csr)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhelper_func_plot_csr_list(G_battles_state_ppp_km_csr)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2nd-Order Spacial Point Patterns Analysis Insights\nBased on the above plots of F and G functions, there is a clustering of points in the dataset. This means that the points are closer to each other that what would be expected under a random distribution.\n\n\nSpatio-temporal KDE layers for Event Types\nA spatio-temporal point process (also called space-time or spatial-temporal point process) is a random collection of points, where each point represents the time and location of an event. Examples of events include incidence of disease, sightings or births of a species, or the occurrences of fires, earthquakes, lightning strikes, tsunamis, or volcanic eruptions.\nThe analysis of spatio-temporal point patterns is becoming increasingly necessary, given the rapid emergence of geographically and temporally indexed data in a wide range of fields. Several spatio-temporal point patterns analysis methods have been introduced and implemented in R in the last ten years.\n\nHelper function for computing spatial-temporal KDE\n\nplot_stkde &lt;- function(acled_sf, year_arg, event_type_arg, mpsz_adm1_owin, plot_title_arg) {\n  # Filter and prepare the data\n  event_type_quarters_combined &lt;- acled_sf %&gt;% \n    filter(year == year_arg & event_type == event_type_arg) %&gt;%\n    select(Quarter_num) %&gt;%\n    as.ppp()\n  \n  # Create a point pattern and apply jitter\n  event_type_quarters_combined_ppp &lt;- rjitter(as.ppp(event_type_quarters_combined), retry=TRUE, nsim=1, drop=TRUE)\n  \n  # Mask the point pattern with the window\n  event_type_quarters_combined_ppp_owin &lt;- event_type_quarters_combined_ppp[mpsz_adm1_owin]\n  \n  # Calculate the space-time kernel density estimate\n  stkde_event_type_data &lt;- spattemp.density(event_type_quarters_combined_ppp_owin)\n  \n  # Print summary\n  print(summary(stkde_event_type_data))\n  \n  # Plot the results\n  par(mfcol=c(2, 3))\n  tims &lt;- c(1, 2, 3, 4)\n  for (i in tims) { \n    if (year_arg == 2024 && i &gt; 2) next\n    plot(stkde_event_type_data, i, \n         override.par=FALSE, \n         fix.range=TRUE, \n         main=paste(plot_title_arg, year_arg, \"Q\", i))\n  }\n}\n\n\nViolence Against CiviliansViolence Against Civilians in Year 2021Violence Against Civilians in Year 2022Violence Against Civilians in Year 2023Violence Against Civilians in Year 2024Explosion & Remote ViolenceStrategic DevelopmentsBattles\n\n\n\n\n\n\nplot_stkde(\n  acled_sf_2021, \n  2021, \n  event_types[\"VIOLENCE_CIVILIANS\"], \n  mpsz_adm1_owin, \n  \"STKDE on Violence Against Civilians in\"\n)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 68653.17 (spatial)\n  lambda = 0.0052 (temporal)\n\nNo. of observations\n  1863 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [-210008.6, 724647.6] x [1072026, 3158467]\n\nTemporal bound\n  [1, 4]\n\nEvaluation\n  128 x 128 x 4 trivariate lattice\n  Density range: [2.201336e-17, 4.548589e-10]\nNULL\n\n\n\n\n\n\n\n\n\n\n\n\nplot_stkde(acled_sf_2022, 2022, event_types[\"VIOLENCE_CIVILIANS\"], mpsz_adm1_owin, \"STKDE on Violence Against Civilians in\")\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 73915.22 (spatial)\n  lambda = 0.0039 (temporal)\n\nNo. of observations\n  2009 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [-210008.6, 724647.6] x [1072026, 3158467]\n\nTemporal bound\n  [1, 4]\n\nEvaluation\n  128 x 128 x 4 trivariate lattice\n  Density range: [3.388548e-15, 3.76366e-10]\nNULL\n\n\n\n\n\n\n\n\n\n\n\n\nplot_stkde(acled_sf_2023, 2023, event_types[\"VIOLENCE_CIVILIANS\"], mpsz_adm1_owin, \"STKDE on Violence Against Civilians in\")\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 66199.04 (spatial)\n  lambda = 0.0085 (temporal)\n\nNo. of observations\n  1646 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [-210008.6, 724647.6] x [1072026, 3158467]\n\nTemporal bound\n  [1, 4]\n\nEvaluation\n  128 x 128 x 4 trivariate lattice\n  Density range: [9.447994e-18, 2.472184e-10]\nNULL\n\n\n\n\n\n\n\n\n\n\n\n\nplot_stkde(acled_sf_2024, 2024, event_types[\"VIOLENCE_CIVILIANS\"], mpsz_adm1_owin, \"STKDE on Violence Against Civilians in\")\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 85036.53 (spatial)\n  lambda = 0.0042 (temporal)\n\nNo. of observations\n  631 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [-210008.6, 724647.6] x [1072026, 3158467]\n\nTemporal bound\n  [1, 2]\n\nEvaluation\n  128 x 128 x 2 trivariate lattice\n  Density range: [6.885204e-14, 5.588596e-10]\nNULL\n\n\n\n\n\n\n\n\n\n\n\nExplosion and Remove Violence in Year 2021\n\nplot_stkde(acled_sf_2021, 2021, event_types[\"EXPLOSIONS_REMOTE_VIOLENCE\"], mpsz_adm1_owin, \"STKDE on Explosion & Remote Violence in\")\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 64492.56 (spatial)\n  lambda = 0.0033 (temporal)\n\nNo. of observations\n  2675 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [-210008.6, 724647.6] x [1072026, 3158467]\n\nTemporal bound\n  [1, 4]\n\nEvaluation\n  128 x 128 x 4 trivariate lattice\n  Density range: [1.232502e-34, 1.148083e-09]\nNULL\n\n\n\n\n\n\n\n\n\nExplosion & Remote Violence in Year 2022\n\nplot_stkde(acled_sf_2022, 2022, event_types[\"EXPLOSIONS_REMOTE_VIOLENCE\"], mpsz_adm1_owin, \"STKDE on Explosion & Remote Violence in\")\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 63373.76 (spatial)\n  lambda = 0.0047 (temporal)\n\nNo. of observations\n  3668 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [-210008.6, 724647.6] x [1072026, 3158467]\n\nTemporal bound\n  [1, 4]\n\nEvaluation\n  128 x 128 x 4 trivariate lattice\n  Density range: [4.611696e-19, 4.201904e-10]\nNULL\n\n\n\n\n\n\n\n\n\nExplosion and Remove Violence in Year 2023\n\nplot_stkde(acled_sf_2023, 2023, event_types[\"EXPLOSIONS_REMOTE_VIOLENCE\"], mpsz_adm1_owin, \"STKDE on Explosion & Remote Violence in\")\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 65917.67 (spatial)\n  lambda = 0.0048 (temporal)\n\nNo. of observations\n  3653 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [-210008.6, 724647.6] x [1072026, 3158467]\n\nTemporal bound\n  [1, 4]\n\nEvaluation\n  128 x 128 x 4 trivariate lattice\n  Density range: [1.198038e-17, 3.967316e-10]\nNULL\n\n\n\n\n\n\n\n\n\nExplosion and Remove Violence in Year 2024\n\nplot_stkde(acled_sf_2024, 2024, event_types[\"EXPLOSIONS_REMOTE_VIOLENCE\"], mpsz_adm1_owin, \"STKDE on Explosion & Remote Violence in\")\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 75483.47 (spatial)\n  lambda = 0.0018 (temporal)\n\nNo. of observations\n  2072 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [-210008.6, 724647.6] x [1072026, 3158467]\n\nTemporal bound\n  [1, 2]\n\nEvaluation\n  128 x 128 x 2 trivariate lattice\n  Density range: [2.097493e-15, 1.970739e-09]\nNULL\n\n\n\n\n\n\n\n\n\n\n\nStrategic Developments in Year 2021\n\nplot_stkde(acled_sf_2021, 2021, event_types[\"STRAT_DEVS\"], mpsz_adm1_owin, \"STKDE on Strategic Developments in\")\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 63831.01 (spatial)\n  lambda = 0.0037 (temporal)\n\nNo. of observations\n  3381 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [-210008.6, 724647.6] x [1072026, 3158467]\n\nTemporal bound\n  [1, 4]\n\nEvaluation\n  128 x 128 x 4 trivariate lattice\n  Density range: [6.909365e-15, 5.347878e-10]\nNULL\n\n\n\n\n\n\n\n\n\nStrategic Developments in Year 2022\n\nplot_stkde(acled_sf_2022, 2022, event_types[\"STRAT_DEVS\"], mpsz_adm1_owin, \"STKDE on Strategic Developments in\")\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 55149.53 (spatial)\n  lambda = 0.0022 (temporal)\n\nNo. of observations\n  4312 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [-210008.6, 724647.6] x [1072026, 3158467]\n\nTemporal bound\n  [1, 4]\n\nEvaluation\n  128 x 128 x 4 trivariate lattice\n  Density range: [1.203656e-18, 9.088899e-10]\nNULL\n\n\n\n\n\n\n\n\n\nStrategic Developments in Year 2023\n\nplot_stkde(acled_sf_2023, 2023, event_types[\"STRAT_DEVS\"], mpsz_adm1_owin, \"STKDE on Strategic Developments in\")\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 61941.92 (spatial)\n  lambda = 0.0054 (temporal)\n\nNo. of observations\n  3115 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [-210008.6, 724647.6] x [1072026, 3158467]\n\nTemporal bound\n  [1, 4]\n\nEvaluation\n  128 x 128 x 4 trivariate lattice\n  Density range: [1.585971e-18, 5.045853e-10]\nNULL\n\n\n\n\n\n\n\n\n\nStrategic Developments in Year 2024\n\nplot_stkde(acled_sf_2024, 2024, event_types[\"STRAT_DEVS\"], mpsz_adm1_owin, \"STKDE on Strategic Developments in\")\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 72805.04 (spatial)\n  lambda = 0.0026 (temporal)\n\nNo. of observations\n  1145 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [-210008.6, 724647.6] x [1072026, 3158467]\n\nTemporal bound\n  [1, 2]\n\nEvaluation\n  128 x 128 x 2 trivariate lattice\n  Density range: [3.368086e-14, 1.294003e-09]\nNULL\n\n\n\n\n\n\n\n\n\n\n\nBattles in Year 2021\n\nplot_stkde(acled_sf_2021, 2021, event_types[\"BATTLES\"], mpsz_adm1_owin, \"STKDE on Battles in\")\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 69194.75 (spatial)\n  lambda = 0.0047 (temporal)\n\nNo. of observations\n  2193 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [-210008.6, 724647.6] x [1072026, 3158467]\n\nTemporal bound\n  [1, 4]\n\nEvaluation\n  128 x 128 x 4 trivariate lattice\n  Density range: [9.43846e-21, 4.51969e-10]\nNULL\n\n\n\n\n\n\n\n\n\nBattles in Year 2022\n\nplot_stkde(acled_sf_2022, 2022, event_types[\"BATTLES\"], mpsz_adm1_owin, \"STKDE on Battles in\")\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 64303.87 (spatial)\n  lambda = 0.0043 (temporal)\n\nNo. of observations\n  3787 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [-210008.6, 724647.6] x [1072026, 3158467]\n\nTemporal bound\n  [1, 4]\n\nEvaluation\n  128 x 128 x 4 trivariate lattice\n  Density range: [2.630951e-17, 3.435047e-10]\nNULL\n\n\n\n\n\n\n\n\n\nBattles in Year 2023\n\nplot_stkde(acled_sf_2023, 2023, event_types[\"BATTLES\"], mpsz_adm1_owin, \"STKDE on Battles in\")\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 67073.04 (spatial)\n  lambda = 0.0042 (temporal)\n\nNo. of observations\n  3944 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [-210008.6, 724647.6] x [1072026, 3158467]\n\nTemporal bound\n  [1, 4]\n\nEvaluation\n  128 x 128 x 4 trivariate lattice\n  Density range: [6.109086e-17, 5.752058e-10]\nNULL\n\n\n\n\n\n\n\n\n\nBattles in Year 2024\n\nplot_stkde(acled_sf_2024, 2024, event_types[\"BATTLES\"], mpsz_adm1_owin, \"STKDE on Battles in\")\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 78864.27 (spatial)\n  lambda = 0.0019 (temporal)\n\nNo. of observations\n  1966 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [-210008.6, 724647.6] x [1072026, 3158467]\n\nTemporal bound\n  [1, 2]\n\nEvaluation\n  128 x 128 x 2 trivariate lattice\n  Density range: [2.097587e-15, 1.722009e-09]\nNULL"
  },
  {
    "objectID": "Take-home_Ex/takehome_1.html#conclusions",
    "href": "Take-home_Ex/takehome_1.html#conclusions",
    "title": "Take-home Exercise 1",
    "section": "Conclusions",
    "text": "Conclusions\nThe ACLED Myanmar dataset definitely holds some interesting insights on how the intensity of each event spreads across to various regions of the country, indicating which state has the most active conflicts going on while allowing us to know which part of Myanmar travelers should steer clear of for their safety."
  },
  {
    "objectID": "Take-home_Ex/takehome_1.html#personal-learnings",
    "href": "Take-home_Ex/takehome_1.html#personal-learnings",
    "title": "Take-home Exercise 1",
    "section": "Personal Learnings",
    "text": "Personal Learnings\nI would have to admit that this exercise has been really challenging and could also be very time-consuming as well due to the speed performance limitations of my computer. Despite all of that, it has also challenged me to find ways to handle an extremely large data set for the first time, making sure that I should plan ahead on what I want to analyse first before writing the code for it.\n\nI believe that the remaining take-home exercises would be more manageable after rigorous and technical experience gained from this take-home exercise."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/hands_on6.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/hands_on6.html",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to compute Global Measures of Spatial Autocorrelation (GMSA) by using spdep package. By the end to this hands-on exercise, you will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\nprovide statistically correct interpretation of GSA statistics."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/hands_on6.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex06/hands_on6.html#overview",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to compute Global Measures of Spatial Autocorrelation (GMSA) by using spdep package. By the end to this hands-on exercise, you will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\nprovide statistically correct interpretation of GSA statistics."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/hands_on6.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06/hands_on6.html#getting-started",
    "title": "Hands-on Exercise 6",
    "section": "Getting Started",
    "text": "Getting Started\n\n9.2.1 The analytical question\nIn spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is No. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China.\n\n\n9.2.2 The Study Area and Data\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\n9.2.3 Setting the Analytical Tools\nBefore we get started, we need to ensure that spdep, sf, tmap and tidyverse packages of R are currently installed in your R.\n\nsf is use for importing and handling geospatial data in R,\ntidyverse is mainly use for wrangling attribute data in R,\nspdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and\ntmap will be used to prepare cartographic quality chropleth map.\n\nThe code chunk below is used to perform the following tasks:\n\ncreating a package list containing the necessary R packages,\nchecking if the R packages in the package list have been installed in R,\n\nif they have yet to be installed, RStudio will installed the missing packages,\n\nlaunching the packages into R environment.\n\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/hands_on6.html#getting-the-data-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex06/hands_on6.html#getting-the-data-into-r-environment",
    "title": "Hands-on Exercise 6",
    "section": "Getting the Data Into R Environment",
    "text": "Getting the Data Into R Environment\nIn this section, you will learn how to bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\nImport shapefile into r environment\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\javilian98\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\nImport csv file into r environment\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R data frame class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nPerforming relational join\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\n\nVisualising Regional Development Indicator\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/hands_on6.html#global-measures-of-spatial-autocorrelation",
    "href": "Hands-on_Ex/Hands-on_Ex06/hands_on6.html#global-measures-of-spatial-autocorrelation",
    "title": "Hands-on Exercise 6",
    "section": "Global Measures of Spatial Autocorrelation",
    "text": "Global Measures of Spatial Autocorrelation\nIn this section, you will learn how to compute global spatial autocorrelation statistics and to perform spatial complete randomness test for global spatial autocorrelation.\n\nComputing Contiguity Spatial Weights\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nIn the code chunk below, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If you look at the documentation you will see that you can pass a “queen” argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\nMore specifically, the code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbours.\n\n\nRow-standardised weights matrix\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\nWhat can we learn from the code chunk above?\n\nThe input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.poly.\nstyle can take values “W”, “B”, “C”, “U”, “minmax” and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nIf zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/hands_on6.html#global-measures-of-spatial-autocorrelation-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex06/hands_on6.html#global-measures-of-spatial-autocorrelation-morans-i",
    "title": "Hands-on Exercise 6",
    "section": "Global Measures of Spatial Autocorrelation: Moran’s I",
    "text": "Global Measures of Spatial Autocorrelation: Moran’s I\nIn this section, you will learn how to perform Moran’s I statistics testing by using moran.test() of spdep.\n\nMaron’s I test\nThe code chunk below performs Moran’s I statistical testing using moran.test() of spdep.\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\n\nAnswer: There is a high standard deviation and a very low p-value, meaning that there is a significant positive spatial correlation from the above.\n\n\n\nComputing Monte Carlo Moran’s I\nThe code chunk below performs permutation test for Moran’s I statistic by using moran.mc() of spdep. A total of 1000 simulation will be performed.\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\nQuestion: What statistical conclustion can you draw from the output above?\n\n\n\nVisualising Monte Carlo Moran’s I\nIt is always a good practice for us the examine the simulated Moran’s I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram by using the code chunk below.\nIn the code chunk below hist() and abline() of R Graphics are used.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n\n\n\n\n\nQuestion: What statistical observation can you draw from the output above?\n\n\nChallenge: Instead of using Base Graph to plot the values, plot the values by using ggplot2 package.\n\n\n# Convert the results to a data frame for ggplot\nbperm_df &lt;- data.frame(Simulated_Morans_I = bperm$res[1:999])\n\n# Create the histogram using ggplot2  \nggplot(bperm_df, aes(x = Simulated_Morans_I)) +\n  geom_histogram(bins = 20, fill = \"blue\", color = \"black\") +\n  geom_vline(xintercept = 0, color = \"red\", linetype = \"dashed\", size = 1) +\n  labs(title = \"Histogram of Simulated Moran's I\",\n       x = \"Simulated Moran's I\",\n       y = \"Frequency\") +\n  theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/hands_on6.html#global-measures-of-spatial-autocorrelation-gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex06/hands_on6.html#global-measures-of-spatial-autocorrelation-gearys-c",
    "title": "Hands-on Exercise 6",
    "section": "Global Measures of Spatial Autocorrelation: Geary’s C",
    "text": "Global Measures of Spatial Autocorrelation: Geary’s C\nIn this section, you will learn how to perform Geary’s C statistics testing by using appropriate functions of spdep package.\n\nGeary’s C test\nThe code chunk below performs Geary’s C test for spatial autocorrelation by using geary.test() of spdep.\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q   \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\n\nAnswer: The Geary C statistic of 0.691, with a standard deviate of 3.6108 and a p-value of 0.0001526, indicates significant negative spatial autocorrelation in GDP per capita across Hunan. This means that regions with high GDP per capita tend to be surrounded by areas with low GDP per capita, suggesting dissimilarity in spatial patterns.\n\n\n\nComputing Monte Carlo Geary’s C\nThe code chunk below performs permutation test for Geary’s C statistic by using geary.mc() of spdep.\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\nAnswer: The observed Geary C statistic of 0.69072, with a p-value of 0.001, indicates significant negative spatial autocorrelation in GDP per capita across Hunan. This strong evidence suggests that areas with high GDP per capita are surrounded by areas with low GDP per capita.\n\n\nVisualising the Monte Carlo Geary’s C\nNext, we will plot a histogram to reveal the distribution of the simulated values by using the code chunk below.\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\") \n\n\n\n\n\n\n\n\n\nQuestion: What statistical observation can you draw from the output?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/hands_on6.html#spatial-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex06/hands_on6.html#spatial-correlogram",
    "title": "Hands-on Exercise 6",
    "section": "Spatial Correlogram",
    "text": "Spatial Correlogram\nSpatial correlograms are great to examine patterns of spatial autocorrelation in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance.Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.\n\nCompute Moran’s I correlogram\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Moran’s I. The plot() of base Graph is then used to plot the output.\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\n\n\n\nBy plotting the output might not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nQuestion: What statistical observation can you draw from the plot above?\n\n\nAnswer: The spatial correlogram reveals significant positive autocorrelation for the first three lags, indicating nearby areas have similar GDP per capita. However, the fourth lag is not significant, and the fifth and sixth lags show significant negative autocorrelation, suggesting that dissimilarities in GDP per capita emerge at greater distances.\n\n\n\nCompute Geary’s C correlogram and plot\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary’s C. The plot() of base Graph is then used to plot the output.\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\n\n\n\nSimilar to the previous step, we will print out the analysis report by using the code chunk below.\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/hands_on6.html#creating-a-lisa-cluster-map",
    "href": "Hands-on_Ex/Hands-on_Ex06/hands_on6.html#creating-a-lisa-cluster-map",
    "title": "Hands-on Exercise 6",
    "section": "Creating a LISA Cluster Map",
    "text": "Creating a LISA Cluster Map\nThe LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.\n\nPlotting Moran scatterplot\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\nThe code chunk below plots the Moran scatterplot of GDPPC 2012 by using moran.plot() of spdep.\n\nnci &lt;- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\n\n\n\n\nNotice that the plot is split in 4 quadrants. The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC. This are the high-high locations in the lesson slide.\n\n\nPlotting Moran scatterplot with standardised variable\nFirst we will use scale() to centers and scales the variable. Here centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.\n\nhunan$Z.GDPPC &lt;- scale(hunan$GDPPC) %&gt;% \n  as.vector \n\nThe as.vector() added to the end is to make sure that the data type we get out of this is a vector, that map neatly into out dataframe.\nNow, we are ready to plot the Moran scatterplot again by using the code chunk below.\n\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")\n\n\n\n\n\n\n\n\n\n\nPreparing LISA map classes\nThe code chunks below show the steps to prepare a LISA cluster map.\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\n\nNext, derives the spatially lagged variable of interest (i.e. GDPPC) and centers the spatially lagged variable around its mean.\n\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)    \n\nThis is follow by centering the local Moran’s around the mean.\n\nLM_I &lt;- localMI[,1] - mean(localMI[,1])\n\nNext, we will set a statistical significance level for the local Moran.\n\nsignif &lt;- 0.05\n\nThese four command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.\n\nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4      \n\nLastly, places non-significant Moran in the category 0.\n\nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\nIn fact, we can combined all the steps into one single code chunk as shown below:\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \nLM_I &lt;- localMI[,1]   \nsignif &lt;- 0.05       \nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4    \nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\n\n\nPlotting LISA map\nNow, we can build the LISA map by using the code chunks below.\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)\n\n\n\n\n\n\n\n\nWe can also include the local Moran’s I map and p-value map as shown below for easy comparison.\n\nQuestion: What statistical observations can you draw from the LISA map above?\n\n\nAnswer: LISA map have larger areas of high-high quadrant compared to the GDPPC map."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/hands_on6.html#hot-spot-and-cold-spot-area-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/hands_on6.html#hot-spot-and-cold-spot-area-analysis",
    "title": "Hands-on Exercise 6",
    "section": "Hot Spot and Cold Spot Area Analysis",
    "text": "Hot Spot and Cold Spot Area Analysis\nBeside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.\nThe term ‘hot spot’ has been used generically across disciplines to describe a region or value that is higher relative to its surroundings (Lepers et al 2005, Aben et al 2012, Isobe et al 2015).\n\nGetis and Ord’s G-Statistics\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics\n\n\n\nDeriving distance-based weight matrix\nFirst, we need to define a new set of neighbours. Whist the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.\nThere are two type of distance-based proximity matrix, they are:\n\nfixed distance weight matrix; and\nadaptive distance weight matrix.\n\n\nDeriving the centroid\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid() on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid(). We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation\nTo get our longitude values we map the st_centroid() function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\n\n\nDetermine the cut-off distance\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\nComputing fixed distance weight matrix\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\n\n\n\nComputing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/hands_on6.html#computing-gi-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex06/hands_on6.html#computing-gi-statistics",
    "title": "Hands-on Exercise 6",
    "section": "Computing Gi statistics",
    "text": "Computing Gi statistics\n\nGi statistics using fixed distance\n\nfips &lt;- order(hunan$County)\ngi.fixed &lt;- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe output of localG() is a vector of G or Gstar values, with attributes “gstari” set to TRUE or FALSE, “call” set to the function call, and class “localG”.\nThe Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.\nNext, we will join the Gi values to their corresponding hunan sf data frame by using the code chunk below.\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\nIn fact, the code chunk above performs three tasks. First, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix(). Next, cbind() is used to join hunan@data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi. Lastly, the field name of the gi values is renamed to gstat_fixed by using rename().\n\n\nMapping Gi values with fixed distance weights\nThe code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\nVariable(s) \"gstat_fixed\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\nQuestion: What statistical observation can you draw from the Gi map above?\n\n\n\nGi statistics using adaptive distance\nThe code chunk below are used to compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e knb_lw).\n\nfips &lt;- order(hunan$County)\ngi.adaptive &lt;- localG(hunan$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n\nMapping Gi values with adaptive distance weights\nIt is time for us to visualise the locations of hot spot and cold spot areas. The choropleth mapping functions of tmap package will be used to map the Gi values.\nThe code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\ngdppc&lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)\n\nVariable(s) \"gstat_adaptive\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\nQuestion: What statistical observation can you draw from the Gi map above?\n\n\nAnswer: There is clear distinction of local Gi values of 4-6 and values of -4 to -2."
  },
  {
    "objectID": "In-class_Ex/ICE_06/ice_06.html",
    "href": "In-class_Ex/ICE_06/ice_06.html",
    "title": "In-class Exercise 06",
    "section": "",
    "text": "pacman::p_load(sf, sfdep, tmap, tidyverse, tmap)\n\nImporting Data\n\nhunan_2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nhunan_sf &lt;- st_read(\n  dsn = \"data/geospatial\",\n  layer = \"Hunan\"\n)\n\nReading layer `Hunan' from data source \n  `C:\\javilian98\\IS415-GAA\\In-class_Ex\\ICE_06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\nhunan_GDPPC &lt;- left_join(hunan_sf, hunan_2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\n\n\nwm_q &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1)\n\nPerforming Global Moran’s I test\n\nglobal_moran_test(\n  wm_q$GDPPC,\n  wm_q$nb,\n  wm_q$wt\n)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\n\nmoranI &lt;- global_moran(\n  wm_q$GDPPC,\n  wm_q$nb,\n  wm_q$wt\n)\n\n\n\n\n\nset.seed(1234)\n\n\nglobal_moran_perm(\n  wm_q$GDPPC,\n  wm_q$nb,\n  wm_q$wt,\n  nsim = 99\n)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\n\nlisa &lt;- wm_q %&gt;%\n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99\n  ),\n  .before = 1) %&gt;%\n  unnest(local_moran)\n\n\nuse p_ii_sim for simulation\nii for local_moran\nmean & median more important\n\nexcessive skewness -&gt; use median column\n\nexcessive: if a lot of number that deviates from 0 (negative/positive)\ncan plot histogram to evaluate\n\nif close to 0 skewness -&gt; use mean column\n\n\nVisualising local Moran’s I\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6, 8)) +\n  tm_layout(\n    main.title = \"local Moran's I of GDPPC\",\n    main.title.size = 1\n  )\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\nVisualising p-value of local Moran’s I and p-value\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6, 8)) +\n  tm_layout(\n    main.title = \"local Moran's I of GDPPC\",\n    main.title.size = 1\n  )\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) +\n  tm_borders(alpha = 0.5) +\n  tm_layout(\n    main.title = \"p-value of local Moran's I\",\n    main.title.size = 1\n  )\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\n\nlisa_sig &lt;- lisa %&gt;%\n  filter(p_ii &lt; 0.05)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") +\n  tm_borders(alpha = 0.5)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\nto create LISA map, need to have the p_ii filter code line"
  },
  {
    "objectID": "In-class_Ex/ICE_06/ice_06.html#install-packages",
    "href": "In-class_Ex/ICE_06/ice_06.html#install-packages",
    "title": "In-class Exercise 06",
    "section": "",
    "text": "pacman::p_load(sf, sfdep, tmap, tidyverse, tmap)\n\nImporting Data\n\nhunan_2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nhunan_sf &lt;- st_read(\n  dsn = \"data/geospatial\",\n  layer = \"Hunan\"\n)\n\nReading layer `Hunan' from data source \n  `C:\\javilian98\\IS415-GAA\\In-class_Ex\\ICE_06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\nhunan_GDPPC &lt;- left_join(hunan_sf, hunan_2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\n\n\nwm_q &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1)\n\nPerforming Global Moran’s I test\n\nglobal_moran_test(\n  wm_q$GDPPC,\n  wm_q$nb,\n  wm_q$wt\n)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\n\nmoranI &lt;- global_moran(\n  wm_q$GDPPC,\n  wm_q$nb,\n  wm_q$wt\n)\n\n\n\n\n\nset.seed(1234)\n\n\nglobal_moran_perm(\n  wm_q$GDPPC,\n  wm_q$nb,\n  wm_q$wt,\n  nsim = 99\n)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\n\n\n\nlisa &lt;- wm_q %&gt;%\n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99\n  ),\n  .before = 1) %&gt;%\n  unnest(local_moran)\n\n\nuse p_ii_sim for simulation\nii for local_moran\nmean & median more important\n\nexcessive skewness -&gt; use median column\n\nexcessive: if a lot of number that deviates from 0 (negative/positive)\ncan plot histogram to evaluate\n\nif close to 0 skewness -&gt; use mean column\n\n\nVisualising local Moran’s I\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6, 8)) +\n  tm_layout(\n    main.title = \"local Moran's I of GDPPC\",\n    main.title.size = 1\n  )\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\nVisualising p-value of local Moran’s I and p-value\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6, 8)) +\n  tm_layout(\n    main.title = \"local Moran's I of GDPPC\",\n    main.title.size = 1\n  )\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) +\n  tm_borders(alpha = 0.5) +\n  tm_layout(\n    main.title = \"p-value of local Moran's I\",\n    main.title.size = 1\n  )\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\n\nlisa_sig &lt;- lisa %&gt;%\n  filter(p_ii &lt; 0.05)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") +\n  tm_borders(alpha = 0.5)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\nto create LISA map, need to have the p_ii filter code line"
  },
  {
    "objectID": "In-class_Ex/ICE_06/ice_06.html#hot-spot-and-cold-spot-analysis",
    "href": "In-class_Ex/ICE_06/ice_06.html#hot-spot-and-cold-spot-analysis",
    "title": "In-class Exercise 06",
    "section": "Hot Spot and Cold Spot Analysis",
    "text": "Hot Spot and Cold Spot Analysis\n\nComputing local Gi* statistics\n\nwm_idw &lt;- hunan_GDPPC %&gt;%\n  mutate(\n    nb = st_contiguity(geometry),\n    wts = st_inverse_distance(\n      nb, geometry,\n      scale = 1, alpha = 1\n    ),\n    .before = 1\n  )\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `wts = st_inverse_distance(nb, geometry, scale = 1, alpha = 1)`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n\n\n\nHCSA &lt;- wm_idw %&gt;%\n  mutate(local_Gi = local_gstar_perm(\n    GDPPC, nb, wt, nsim = 99\n  ), .before = 1) %&gt;%\n  unnest(local_Gi)\n\nHCSA\n\nSimple feature collection with 88 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 19\n   gi_star cluster   e_gi     var_gi std_dev p_value p_sim p_folded_sim skewness\n     &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.0416 Low     0.0114 0.00000641  0.0493 9.61e-1  0.7          0.35    0.875\n 2 -0.333  Low     0.0106 0.00000384 -0.0941 9.25e-1  1            0.5     0.661\n 3  0.281  High    0.0126 0.00000751 -0.151  8.80e-1  0.9          0.45    0.640\n 4  0.411  High    0.0118 0.00000922  0.264  7.92e-1  0.6          0.3     0.853\n 5  0.387  High    0.0115 0.00000956  0.339  7.34e-1  0.62         0.31    1.07 \n 6 -0.368  High    0.0118 0.00000591 -0.583  5.60e-1  0.72         0.36    0.594\n 7  3.56   High    0.0151 0.00000731  2.61   9.01e-3  0.06         0.03    1.09 \n 8  2.52   High    0.0136 0.00000614  1.49   1.35e-1  0.2          0.1     1.12 \n 9  4.56   High    0.0144 0.00000584  3.53   4.17e-4  0.04         0.02    1.23 \n10  1.16   Low     0.0104 0.00000370  1.82   6.86e-2  0.12         0.06    0.416\n# ℹ 78 more rows\n# ℹ 10 more variables: kurtosis &lt;dbl&gt;, nb &lt;nb&gt;, wts &lt;list&gt;, NAME_2 &lt;chr&gt;,\n#   ID_3 &lt;int&gt;, NAME_3 &lt;chr&gt;, ENGTYPE_3 &lt;chr&gt;, County &lt;chr&gt;, GDPPC &lt;dbl&gt;,\n#   geometry &lt;POLYGON [°]&gt;\n\n\n\n\nVisualising Gi*\n\nHCSA_sig &lt;- HCSA %&gt;%\n  filter(p_sim &lt; 0.05)\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(HCSA) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig) +\n  tm_fill(\"gi_star\") +\n  tm_borders(alpha = 0.5)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\ngstat is for hotspot and coldspot\nLISA for clusters"
  }
]